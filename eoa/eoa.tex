\chapter{Intelligent data acquisition blends targeted and discovery methods.}

\section{Summary}

A MS method is described here that can reproducibly identify hundreds of peptides across multiple experiments. The method uses intelligent data acquisition (IDA) to precisely target peptides while simultaneously identifying thousands of other, non-targeted peptides in a single nano-LC-MS/MS experiment. We introduce an online peptide elution order alignment (EOA) algorithm that targets peptides based on their relative elution order, eliminating the need for retention time-based scheduling. We have applied this method to target 500 mouse peptides across six technical replicate nano-LC-MS/MS experiments and were able to identify 440 of these in all six, compared to only 201 peptides using data-dependent acquisition (DDA). A total of 3,757 other peptides were also identified within the same experiment, illustrating that this hybrid method does not eliminate the novel discovery advantages of DDA. The method was also tested on a set of mice in biological quadruplicate and increased the number of identified target peptides in all four mice by over 80\% (826 vs. 459) compared with the standard DDA method. We envision real-time data analysis as a powerful tool to improve the quality and reproducibility of proteomic datasets.

\section{Introduction}

Large-scale proteomic studies make use of a variety of tools and techniques to achieve depth and wide coverage of proteomes. The most popular method for sequencing proteomes is shotgun sequencing where peptides are digested from extracted proteins, separated with chromatography (HPLC), and then mass analyzed using mass spectrometry (MS).\cite{mudpit,mudpit2} Since complex proteomes can encompass thousands of proteins, leading to millions of peptides, deciding how to allocate the limited mass spectrometer bandwidth is key to successful analysis.\cite{100000} By far the most successful method for this time management is data dependent acquisition (DDA), where intact peptide precursors are first mass analyzed (MS1), specific \mz{} features are then selected to undergo fragmentation, and finally the fragment ions are mass analyzed again (MS/MS). This process is repeated throughout the LC separation, resulting in a large collection of MS and MS/MS spectra. Peptides are eventually identified from the fragmentation spectra and then grouped together back into their parent proteins.\cite{sequest,sadygov,venable,panda} This approach has produced outstanding results in the past decade, but, due to variety of reasons (e.g., large protein dynamic range, speed of MS instrumentation, separation efficiency, etc.) undersampling of proteomes is very common. In other words, not every peptide is identified in every LC-MS/MS experiment. Incomplete datasets limit the questions researchers can answer, especially when biological replication is used to increase statistical power, many measurements become worthless if they cannot be measured reproducibly.\cite{quant} As proteomics seeks to answer global biological questions, reproducible peptide identification between datasets is mandated.\cite{ideker,msbp,molloy}

Many studies have outlined the problem of poor peptide reproducibility.\cite{liu,mrm,tabb,bigtime,pachl} Aebersold succinctly summarized that irreproducibility is a multifaceted issue, depending on user experience, equipment, and data analysis, among others.\cite{aebersold} He outlines that there are two main approaches in tackling irreproducibility. First, exhaustively identify every peptide in a sample -- an approach that is becoming more feasible as technology improves.\cite{thakur,nagaraj,onehour} The more common approach, as many other researchers have embarked on, is to focus on a smaller subset of peptides and to thoroughly identify and quantify those using targeted methods.\cite{savitski} Methods such as selected reaction monitoring (SRM) are powerful and reproducible, but are low throughput, targeting a few hundred peptides at most.\cite{lange,picotti1,picotti2} To improve identification reproducibility and throughput, targeted methods almost exclusively rely on retention time-based scheduling, segmenting the MS duty cycle among the target peptides. In SRM methods, a series of MS/MS transitions for each targeted peptide is automatically collected at the appropriate retention time (RT), removing the dependence on MS1 detection. This requires precise knowledge of the peptide retention time for the LC-MS system and is low throughput as only one set of transitions are monitored at a given point in time. Recent work on intelligent SRM (iSRM) increases throughput by monitoring only a subset of transitions for each target, switching to normal SRM when these transitions are detected.\cite{isrm} We sought to expand upon the idea of intelligent real-time switching of methods by combining the enhanced reproducibility of targeted scheduled methods with the novel discovery advantages of DDA in a single hybrid method. Our goals were three-fold: first, to develop a method that increases the throughput of targeting; second, to replace retention-time based scheduling and its laborious method development with a more robust and straightforward peptide elution ordering; and last, to maintain the discovery aspect of DDA sampling while simultaneously targeting a subset of peptides.

In the last decade, a few computational approaches have been aimed at solving the problem of poor reproducibility. The concept of accurate mass tags (AMT) was first introduced by Smith et. al. as a means to identify peptides in multiple runs based on accurate mass and retention time.\cite{smith} This concept was further expanded with PepMiner and PEPPeR, tools for clustering features among multiple datasets.\cite{pepminer,pepper} Most notably, Prakash et. al. introduce the concept of aligning multiple MS datasets based on peptide relative elution order into signal maps.\cite{prakash} To date, these and other computational methods\cite{radulovic,listgarten,shen,zhang,lin,bateman} have been performed post-acquisition, attempting to improve already collected data. We seek to improve the reproducibility at the source by improving the algorithms the MS uses to select precursors to fragment. We and others have proposed using real-time data analysis and dynamic MS control as a means for improving the quality of acquired spectra.\cite{inseq,graumann,webber} Here we present our findings on combining accurate mass, elution orders, and real-time data analysis to improve the sampling reproducibility of the MS.

\section{Results and discussion}

\subsection*{Irreproducible Peptide Identification.}
In data dependent acquisition (DDA) peptide precursors are selected for fragmentation based on intensity in a MS1 survey scan. This straightforward approach has proven to be a simple and powerful technique. However, it is pestered with inconsistent sampling, and therefore, irregular peptide identification between experiments. The DDA method is inherently stochastic in nature, depending heavily on the consistency of the input data (MS1) to deliver reproducible peptide identification (MS/MS). Even the slightest change in the chromatography or ionization efficiencies will have repercussions on the collection of the whole dataset (e.g., the butterfly effect). To characterize the extent these minor changes have on the reproducibility of peptide identifications, six replicate injections of a tryptic digest of yeast whole cell lysate were analyzed using DDA on the same nano-LC-MS/MS system over a span of ten days. On average, each experiment identified 13,289 $\pm$ 340 unique peptide sequences (I/L ambiguity removed) at a 1\% FDR, indicating a highly consistent separation and nearly identical instrument performance. Of the 23,919 unique peptides identified in total, only 5,404 (22.6\%) of those peptide were identified in all six experiments (Figure \ref{fig:eoa1}).
\begin{sidewaysfigure}[p]
	\centering
	\includegraphics[width=\columnwidth]{eoa/EOA 1.png}
	\mycaption{Overlap of peptide identification among the analysis of six technical replicates}{Six nano-LC-MS/MS experiments produced 23,919 unique peptide identifications in total, but only one fifth of the identifications were observed in all six replicates. A large percentage (31.2\%) of the peptides were only detected in one of the six experiments.}
	\label{fig:eoa1}
\end{sidewaysfigure}
A significant portion were only identified once (7,474 31.2\%) while the remaining peptides were divided between two and five experiments. This clearly demonstrates the irreproducibility of DDA sampling on the same peptide solution. The reproducibility of identified protein groups fares better; 1,708 of 3,054 (56\%) protein groups were identified in every experiment. The higher overlap percentage is because many different peptides can make up one protein group, minimizing the importance of identifying the same peptides in all experiments. However, post translation modification (PTM) analysis requires identification of the same sites to compare between experiments, demanding the need for high peptide overlap. PTM analysis and quantitation is becoming more prominent in the literature, thus making this a growing problem in the field. Two reasons can be attributed to the poor reproducibility of stochastic DDA sampling. First, precursors having low signal-to-noise (S/N) are affected first by changes in chromatography and ionization. For example, a precursor with a maximal S/N of 4 may have been sampled and identified in one experiment, but in the next experiment the S/N may have dropped below the detection threshold and excluded from being sampled. This is evident when 8,883 MS1 features from peptides identified in one or all of the six experiments were examined for their maximal S/N (Figure \ref{fig:eoas1}).
 \begin{sidewaysfigure}[p]
 	\centering
 	\includegraphics[width=0.9\columnwidth]{eoa/EOA S1.png}
 	\mycaption{Distribution of signal-to-noise ratios of reproducible and irrepoducible peptide identifications}{Peptides that were identified in 1 of 6 or 6 of 6 DDA top-15 experiments were analyzed for their maximal MS1 signal-to-noise (S/N). A larger percentage of those peptides seen only once appear at lower signal-to-noise values, indicating that MS1 signal intensity for reproducible identifications.}
 	\label{fig:eoas1}
 \end{sidewaysfigure}
For peptides identified once 2,707 (30.5\%) had a maximal S/N $\leq$ 4 while only 814 (9.2\%) precursors identified in every experiment had similar maximum S/N. The other reason for inconsistent peptide identification is increased MS1 spectral complexity, specifically its effect on charge-state assignment. In proteomic MS/MS workflows, precursors are often only selected when they exhibit a well-defined charge state -- usually where \textit{z} > 1, as singly charged precursors fragment poorly and usually do not lead to positive identifications. Increases in spectral complexity hinder the charge-state determination algorithms, especially for low S/N precursors. This results in skipping precursors even if its signal-to-noise is above the sampling threshold.

\subsection{Retention Time Based Targeting.}

When good peptide identification reproducibility is needed, retention time (RT) based targeting, i.e., scheduling, has been the method of choice. Here, peptides of interest are assigned an expected elution time and MS/MS are triggered, regardless of MS1 detection, during the appropriate time range. This avoids the two issues with DDA sampling described above and enables much higher reproducibility. However, such methods are laborious to construct and maintain identical LC and MS parameters must be kept between experiments to minimize any variances in retention times of the peptides.

To assess the degree of variance in peptide retention times that occur in normal nano-LC-MS/MS experiments, two of the yeast DDA experiments described above, performed nine days apart, were compared. The first experiment (July $22^{nd}$, D0) produced 13,529 unique peptides and the second experiment (July $31^{st}$, D9) identified 13,433 yeast peptides. Together, 7,589 peptides were in common and the apex of their retention time in each experiment is plotted in Figure \ref{fig:eoa2}A.
\begin{figure}[p]
	\centering
	\includegraphics[width=0.65\columnwidth]{eoa/EOA 2.png}
	\mycaption{Retention time deviation between matched LC-MS/MS experiments}{To assess the deviation in retention times for matched samples two identical nano-LC-MS/MS experiments were run nine days apart on the same LC-MS system. (A) The relationship between apex retention times of the 7,589 unique peptides common between experiments display a high degree of linearity ($R^2$ = 0.9989) but a skewed slope and non-zero intercept (m = 1.033; b = -0.647).  (B) The average deviation from unity was nearly a minute off ($\mu$ = -0.805 min), with a broad distribution over 2 minutes wide. (C) Peptides ranked by their relative elution order exhibit a normal distribution around zero ($\mu$ =-1.097).}
	\label{fig:eoa2}
\end{figure} 

The relationship between retention times of matched peptides is highly linear ($R^2$ = 0.9989) but has a non-unity slope and non-zero intercept (m = 1.033; b = -0.647). While the slope is very close to 1, even the slightest deviation (0.033), compounded over time, leads to large RT differences late in the separation (e.g. \textasciitilde1.6 min shift at 70 min). On the whole, the average RT deviation was nearly a minute ($\mu$ = -0.805 min) with a broad distribution over a two minute range (Figure \ref{fig:eoa2}B). Typically, the assigned peptide elution times must be corrected to encompass this shift.

We hypothesize that -- due to the degree of linearity in peptide retention times,we could avoid these corrections by scheduling peptides based on their relative elution order (EO), opposed to their absolute retention time. Under similar LC conditions (i.e., same particles, temperature, column length, phase, etc.) peptides elute in the same relative order regardless of separation duration or slope. For example, if peptide 'A' elutes before peptide 'B' in a 30 minute LC gradient, the same ordering is preserved with a 60 minute LC gradient, even if the absolute retention times vary greatly. When many peptidesâ€™ elution orders are taken into account (e.g., 1000s of peptides) they provide a simple way to correct for elution variation dynamically. This is evident when we took the 7,589 peptides and rank ordered them based on their apex retention times for both the D0 and D9 experiments and plotted the difference between matched peptides (Figure \ref{fig:eoa2}C). Here the values are normally distributed around zero ($\mu$ =-1.097) with a full width at half maximum (FWHM) of only \textasciitilde100. Elution order can be useful even under extreme differences in chromatographic conditions as well.
\begin{figure}[p]
	\centering
	\includegraphics[width=0.5\columnwidth]{eoa/EOA S2.png}
	\mycaption{Two technical replicates of a yeast DDA top-15 method using two different LC gradients}{(A) Retention times for matched peptides between the two gradients is linear but not 1:1. (B) An average deviation of 10 min exists between the two experiments. (C) Rank elution orderings of matched peptides between the two gradients show a highly linear relationship that is exactly 1:1. (D) The average deviation in elution order for matched peptides is symmetric around 0.}
	\label{fig:eoas2}
\end{figure}

To simulate dynamic chromatographic conditions, we separated yeast peptides under two different LC gradient profiles. The resulting peptide identifications were again matched between the runs and the retention time difference was plotted (Figure \ref{fig:eoas2}A). These data show an average deviation of ten minutes between the two gradients (Figure \ref{fig:eoa2}B), but when ranked by their elution orders, the two experiments show a linear slope of 1 with a normal distribution of ranked elution orders around zero (Figure \ref{fig:eoa2}C\&D). 

\subsection*{Real-time Elution Ordering Alignment.}

We reasoned that using elution order could improve the irreproducible sampling of DDA -- similarly to scheduled methods, but on a larger scale and more robustly. The question shifts from ''what retention time is it?'' as scheduled methods ask, to ''what is the current elution order?'' By knowing which peptides are currently eluting from the LC, combined with the a priori knowledge of their elution order, we predict with high fidelity what peptides are going to subsequently elute. 

Prior knowledge is needed of the sample to adequately calculate the elution orders of the peptides in the sample. With time-based scheduled methods, many cursory experiments are performed to optimize the retention times of the targeted peptides. To reduce variances in retention times, it's vital that these initial experiments are conducted exactly the same as the targeted experiments. In stark contrast, elution orders can be determined using a variety of methods. First, much work has been devoted to determining peptide hydrophobicities from theoretical calculations of the amino acid sequence.\cite{ssrcalc,ssrcalc2,petritis,spicer} A simple list of peptides, ordered by their hydrophobicities, can produce a highly linear elution ordering. Second, previously collected data of the sample can produce an accurate elution ordering as long as the LC conditions are similar enough. This enables the combination of multiple datasets to produce a single elution order vs. \mz{} map (elution order map, EOM), regardless of their individual separation durations. This is accomplished by rank ordering all the peptide identifications in a given run and normalizing their orderings between 0 and 100 (where 100 represents the last eluting peptide). These normalized values are then matched between experiments and aligned using a simple algorithm to produce the final EOM as shown in Figure \ref{fig:eoa3}A.
\begin{sidewaysfigure}[p]
	\centering
	\includegraphics[width=\columnwidth]{eoa/EOA 3.png}
	\mycaption{Real-time elution order alignment algorithm}{After 46.3 minutes into a LC-MS/MS experiment, an MS1 scan is performed (A) and m/z features are matched to a 2D ion map stored on the instrument. (B) 21 of the peaks match 80 features in the ion map at a 10 ppm tolerance. Of these, over half (41 of 80) were mapped to one elution order bin (51 elution order). (C) A rolling elution order range is continually updated throughout the LC-MS/MS experiment.}
	\label{fig:eoa3}
\end{sidewaysfigure}
Lastly, the most robust method for determining peptide elution orders is to perform a discovery experiment right before the targeted experiment. Regardless of how elution order is determined, the final EOM is uploaded onto the instrument and is accessed throughout the course of the subsequent analyses.

Prior to targeted analysis, a list of peptide targets, along with their relative elution orders are also uploaded to the instrument (Figure \ref{fig:eoa4}B).
\begin{sidewaysfigure}[p]
	\centering
	\includegraphics[width=\columnwidth]{eoa/EOA 4.png}
	\mycaption{Selection of targets within elution order range}{Following determination of the current elution order range (A), targets sharing a similar elution order are selected (C). Peptide targets within the elution order range are sorted based on when they were last sampled for MS/MS, leaving targets that have been waiting the longest. Those peptides are immediately sampled, regardless of MS1 detection (D). Remaining MS/MS events are automatically filled with DDA chosen m/z features.}
	\label{fig:eoa4}
\end{sidewaysfigure} 
Each target is assigned an elution order range depending on how long it was identified in the discovery experiments (see Figure \ref{fig:eoa4}C for zoom in). During the targeted analysis, instead of relying on absolute retention time to trigger targeted MS/MS, determining the current elution order becomes the main goal of the method. We have designed an online peptide elution order alignment (EOA) algorithm that takes a single MS1 spectrum and computes the current elution order therefrom. In brief, following MS1 acquisition, the EOA algorithm takes the most intense \mz{} feature and extracts all the elution order values from the uploaded EOM at a narrow \mz{} tolerance (e.g., 10 ppm) (Figure \ref{fig:eoa3}A). Each \mz{} feature is matched in a similar fashion and the resulting EO values are stored in a separate array (Figure 3B). In this example MS1, 21 \mz{} features matched a total of 80 EO values. When analyzed, 41 of these values are contained within a single 1 EO-wide bin. This indicates with high confidence that the current elution order is near this maximum. To determine the elution order precisely, the algorithm then calculates the 95\% confidence interval around the max EO bin and stores the minimum (50.02) and maximum (51.64) elution order. This process is repeated for each MS1 and over time the calculated elution order range constructs a rolling-average as shown in Figure 3C. The EOA algorithm is expedient, taking on average 26 ms per MS1 to execute and does not induce a statistically significant change in the total number of MS/MS scans performed (Figure \ref{fig:eoas3}).
\begin{figure}[p]
	\centering
	\includegraphics[width=0.8\columnwidth]{eoa/EOA S3.png}
	\mycaption{Duty cycle of elution order alignment algorithm}{(A) The elution order alignment (EOA) algorithm is expedient and induces only a slight increase in the MS1 duty cycle compared to normal DDA method (\textasciitilde26 ms). (B) The distributions of scan times for IDA is bimodal because the EOA algorithm can be triggered every other MS1, because the current elution order changes only slightly between consecutive MS1 scans.}
	\label{fig:eoas3}
\end{figure} 

Once the current elution order range is determined, peptides sharing a similar elution order are selected for MS/MS analysis. Briefly, the current elution order range is intersected with the target peptides already uploaded on the instrument (Figure \ref{fig:eoa4}B) and overlapping peptides are stored as potential targets (Figure \ref{fig:eoa4}C). These peptides have a high probability of eluting next since they share very similar EO values with the current overall EO value. Since there can be many potential targets at any given time, they are filtered based on how long since they were last sampled, this is to prevent oversampling of any one target. Peptides that have been waiting the longest (i.e., > 5s) are automatically triggered for MS/MS analysis regardless of MS1 detection. Unfilled MS/MS events are then populated using normal DDA top-N approaches, excluding any \mz{} previously selected to be targeted (Figure \ref{fig:eoa4}D). This data collection scheme enables repetitive, consistent targeting of multiple peptides over their elution, while allowing DDA scans to facilitate discovery. Quantitative strategies such as PRM can be used in conjunction with the EOA algorithm (Figure \ref{fig:eoas4}).
\begin{figure}[p]
	\centering
	\includegraphics[width=0.6\columnwidth]{eoa/EOA S4.png}
	\mycaption{Parallel reaction monitoring (PRM) scan sequences obtainable using the IDA method}{(A) The peptide FLTTNFLK was MS/MS sampled approximately every 6 seconds over its elution profile. The b- and y-ions intensities were tracked over time to provide quantitative results.}
	\label{fig:eoas4}
\end{figure}  

\bibliographystyle{ieeetr}
\bibliography{eoa}