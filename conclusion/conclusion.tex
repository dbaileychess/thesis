\chapter{The Future of Intelligent Data Acquisition Methods}

The work presented here describes technologies on the forefront of mass spectrometry acquisition methods. It takes data analysis algorithms--typically perform post-acquisition, and uses them during the acquisition of MS spectra to improve the quality of data. The ability to immediately analyze data and make informed decisions on what to do next is important in separation-based analyses, where an analyte only has a narrow window of time that it can be probed. And given the size of the proteomic samples, where thousands of proteins are digested into hundred of thousands of peptides, time-management becomes the main challenge. How should the mass spectrometer spend its limited resources to gain the most information about a sample?

The most straightforward answer is to speed things up, make the mass spectrometer faster and more sensitive so it can spend less time per analyte, and therefore gains access to more of the proteome. The fastest mass spectrometers can achieve nearly 20 Hz scan rates while still being sensitive and selective enough to identify peptides. But increased speed can only solve so much of the time-management problem. Take yeast for example, with approximately 6,600 proteins that produce half a million peptides when digested with trypsin (1 missed cleavage), how long would it take to sample each peptide? Assuming a 20 Hz acquisition rate, a 100\% identification rate, and a perfect LC separation, it would take at least 7 hours constitutive operation to sample each one once. Of course one does not need to identify every peptide in a solution to learn about the proteins in the sample. This just illustrates that speed alone will not immediately solve the challenge. 

Our approach in solving this time-management challenge is to provide the mass spectrometer with more options and more information through software modifications.
Software improvements are ideal, since they cost next to nothing to deploy and can modify existing instruments without hardware upgrades. However, since intelligent methods are still in their infancy, much work needs to be done. The following sections outline the two biggest hurdles that need to be jumped in order that intelligent acquisition methods are widely used. First is the lack of accessibility for other researchers to perform and use these methods in their own work. And secondly,

\section{Accessibility of Intelligent Mass Spectrometers}
There are two main methods for increasing the intelligence of mass spectrometers. The first would be if there is a home built mass spectrometer that is controlled by custom controllers and software. The other way is to modify and extend commercially available mass spectrometers with the desired abilities. For large scale proteomic work, the former approach is not straightforward, as a vast majority of large-scale publication use commercial instruments for data acquisition. Custom built mass spectrometers often focus on a very specific task (e.g., new mass analyzer, new dissociation technique, etc.) and rarely are geared for high-performance, large-scale protein experiments. Even if a researcher built a mass spectrometer capable of these types of experiments, there is no easy way to disseminate the technology, short of starting a company themselves. Commercial instruments, on the other hand, are primarily developed to take the best technologies available and combine them into one unified package. This results in a powerful and stable instrument that can handle the largest experiments. However, in order to protect their intellectual property (IP), instrument vendors are usually highly restrictive in how their instruments are used. This makes implementing novel acquisition methods very difficult, and therefore general acceptance of new methods is slow. Thus, the most important factor in the future of intelligent data acquisition methods is increasing the accessibility and availability.

Probably the best way to propel the development of intelligent acquisition methods forward is to increase its accessibility and availability to researchers. This is challenging since instrument vendors are highly protective of their products; they have to protect their intellectual property and public imagine while providing state-of-the-art technologies to consumers. They cannot release access to their control logic in fears of competitors gaining an edge. They also worry that supporting third-party programs for their instruments could damage their reputation. Our lab, which has developed multiple technologies now commercialized, know first hand the care instrument vendors take in releasing third-party technologies to the general consumer. The following section will briefly discuss how developing new technologies is currently done and improvements that could be made to facilitate the dissemination of intelligent mass spectrometers.  

\subsection*{Instrument Programming.}
To develop new MS instrument methods, researchers are typically given special access to the instrument's firmware by a vendor. This allows them direct control of the instrument and gives them the ability to alter the methods as they see fit. Of course care is taken to ensure confidentiality and protect IP. However, this method of development is not ideal and is more of band-aid then a real solution. The instrument vendors never developed a system to support third-party methods, so when the first researchers wanted to extend the instrument capabilities, the quickest solution was to give them access to the source code, just like they were an internal developer.

A better model of development would be to develop and deploy an application programming interface (API) to control the instrument. Here, the vendor would provide a set of software tools and objects to enable access to different parts of the instrument. They would have fine-grain support on what they make available to the end user and what they keep hidden, thus alleviating some IP concerns. This technique also could provide error checking, preventing the user from setting some value that could potentially damage the instrument or injure someone. In fact, some instrument vendors have started down this path. Thermo has recently released an API for their Q Exactive mass spectrometer to enable third-party support. This allows the user to program in an more advanced language then is used on the instrument itself. For example, the Q Exactive's firmware is written in Python (a scripting language), while the API is written in C\# (a compiled, and generally a more powerful language).

The biggest challenge though is convincing the instrument vendors to support such a technology, as it requires time and resources to develop and maintain. But if anything can be learned from community-developed applications on the internet (i.e., crowd sourcing), much can be gained when many people are working on a common problem. It may well behoove vendors to provide such access to potentially gain dozens of developers.

\section{tt}
Behind any feature or tool, there always lies the question ''Is this needed?'' Can some other tool provide the benefits, or are the benefits even worth having.